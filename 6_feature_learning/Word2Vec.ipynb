{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec字嵌入(word embedding)\n",
    "\n",
    "Word2vec是根據字詞在鄰近距離的方法做訓練。input layer是一個語料庫所有字詞的one-hot vector，假設語料庫有1,000個字，只有目前輸入的字它的位置是1，其餘為0的向量。輸入之後會經過一層hidden layer，hidden layer的數量就是我們要將字詞轉成向量的維度大小。輸出的神經元數量與輸入一樣，都是語料庫的大小。而其中的數值則是目前字詞的context window內的鄰近字詞機率。如果是鄰近字詞，該位置的數值越接近1越好，如果不是，就越接近0越好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Word2vec字嵌入的gensim套件\n",
    "\n",
    "word2vec是gensim套件最主要的演算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#設置日誌紀錄器(logger)，觀看詳細的訓練過程\n",
    "logging.basicConfig(format='%(asctime)s: %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec, Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = word2vec.Text8Corpus('./data/text8.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.word2vec.Text8Corpus object at 0x000001C0551619D0>\n"
     ]
    }
   ],
   "source": [
    "#這是計算字嵌入的特定演算法\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> gensim需要可以迭代的物件(如list、generator、tuple等等)，裡面是切分成字符(tokenized)的句子。設置好這個變數之後，就可以讓gensim開始學習工作了。\n",
    "\n",
    "__gensim.models.Word2Vec參數__\n",
    "- min_count:忽略出現次數小於該值的字詞\n",
    "- size:要學習的字詞維度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-07 21:59:22,625: INFO : collecting all words and their counts\n",
      "2020-09-07 21:59:22,679: INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-09-07 21:59:31,814: INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2020-09-07 21:59:31,814: INFO : Loading a fresh vocabulary\n",
      "2020-09-07 21:59:32,861: INFO : effective_min_count=1 retains 253854 unique words (100% of original 253854, drops 0)\n",
      "2020-09-07 21:59:32,865: INFO : effective_min_count=1 leaves 17005207 word corpus (100% of original 17005207, drops 0)\n",
      "2020-09-07 21:59:34,426: INFO : deleting the raw counts dictionary of 253854 items\n",
      "2020-09-07 21:59:34,438: INFO : sample=0.001 downsamples 36 most-common words\n",
      "2020-09-07 21:59:34,440: INFO : downsampling leaves estimated 12819131 word corpus (75.4% of prior 17005207)\n",
      "2020-09-07 21:59:35,613: INFO : estimated required memory for 253854 words and 20 dimensions: 167543640 bytes\n",
      "2020-09-07 21:59:35,613: INFO : resetting layer weights\n",
      "2020-09-07 22:01:19,967: INFO : training model with 3 workers on 253854 vocabulary and 20 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-09-07 22:01:20,976: INFO : EPOCH 1 - PROGRESS: at 4.29% examples, 548174 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:21,980: INFO : EPOCH 1 - PROGRESS: at 8.82% examples, 559052 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:22,991: INFO : EPOCH 1 - PROGRESS: at 13.40% examples, 566096 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:23,998: INFO : EPOCH 1 - PROGRESS: at 17.99% examples, 570359 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:25,008: INFO : EPOCH 1 - PROGRESS: at 22.75% examples, 577186 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:26,015: INFO : EPOCH 1 - PROGRESS: at 27.57% examples, 584091 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:01:27,025: INFO : EPOCH 1 - PROGRESS: at 32.39% examples, 589222 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:01:28,025: INFO : EPOCH 1 - PROGRESS: at 37.10% examples, 591403 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:29,035: INFO : EPOCH 1 - PROGRESS: at 42.21% examples, 598016 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:30,049: INFO : EPOCH 1 - PROGRESS: at 47.27% examples, 602477 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:01:31,056: INFO : EPOCH 1 - PROGRESS: at 52.09% examples, 603755 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:32,062: INFO : EPOCH 1 - PROGRESS: at 57.08% examples, 606948 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:33,063: INFO : EPOCH 1 - PROGRESS: at 61.55% examples, 604373 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:01:34,079: INFO : EPOCH 1 - PROGRESS: at 66.61% examples, 606823 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:35,095: INFO : EPOCH 1 - PROGRESS: at 71.55% examples, 608148 words/s, in_qsize 5, out_qsize 1\n",
      "2020-09-07 22:01:36,100: INFO : EPOCH 1 - PROGRESS: at 76.72% examples, 610537 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:37,106: INFO : EPOCH 1 - PROGRESS: at 81.66% examples, 611308 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:01:38,112: INFO : EPOCH 1 - PROGRESS: at 86.07% examples, 608591 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:01:39,116: INFO : EPOCH 1 - PROGRESS: at 90.71% examples, 607962 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:01:40,122: INFO : EPOCH 1 - PROGRESS: at 95.47% examples, 607663 words/s, in_qsize 4, out_qsize 1\n",
      "2020-09-07 22:01:41,025: INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-07 22:01:41,028: INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-07 22:01:41,037: INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-07 22:01:41,038: INFO : EPOCH - 1 : training on 17005207 raw words (12817725 effective words) took 21.1s, 608493 effective words/s\n",
      "2020-09-07 22:01:42,044: INFO : EPOCH 2 - PROGRESS: at 4.76% examples, 608777 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:01:43,053: INFO : EPOCH 2 - PROGRESS: at 9.70% examples, 614474 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:01:44,076: INFO : EPOCH 2 - PROGRESS: at 14.76% examples, 620391 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:45,089: INFO : EPOCH 2 - PROGRESS: at 19.69% examples, 621300 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:01:46,101: INFO : EPOCH 2 - PROGRESS: at 24.63% examples, 622307 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:01:47,110: INFO : EPOCH 2 - PROGRESS: at 29.57% examples, 624505 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:48,116: INFO : EPOCH 2 - PROGRESS: at 34.39% examples, 624129 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:01:49,117: INFO : EPOCH 2 - PROGRESS: at 38.74% examples, 615950 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:50,128: INFO : EPOCH 2 - PROGRESS: at 43.39% examples, 613131 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:51,137: INFO : EPOCH 2 - PROGRESS: at 48.56% examples, 618067 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:52,145: INFO : EPOCH 2 - PROGRESS: at 53.38% examples, 618032 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:53,155: INFO : EPOCH 2 - PROGRESS: at 57.61% examples, 611477 words/s, in_qsize 5, out_qsize 1\n",
      "2020-09-07 22:01:54,158: INFO : EPOCH 2 - PROGRESS: at 62.14% examples, 608996 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:55,165: INFO : EPOCH 2 - PROGRESS: at 67.08% examples, 610335 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:01:56,171: INFO : EPOCH 2 - PROGRESS: at 71.90% examples, 610757 words/s, in_qsize 5, out_qsize 1\n",
      "2020-09-07 22:01:57,194: INFO : EPOCH 2 - PROGRESS: at 76.72% examples, 609693 words/s, in_qsize 5, out_qsize 1\n",
      "2020-09-07 22:01:58,197: INFO : EPOCH 2 - PROGRESS: at 80.78% examples, 604027 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:01:59,210: INFO : EPOCH 2 - PROGRESS: at 85.48% examples, 603518 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:00,212: INFO : EPOCH 2 - PROGRESS: at 90.01% examples, 602400 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:01,221: INFO : EPOCH 2 - PROGRESS: at 94.94% examples, 603366 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:02,209: INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-07 22:02:02,219: INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-07 22:02:02,224: INFO : EPOCH 2 - PROGRESS: at 100.00% examples, 605218 words/s, in_qsize 0, out_qsize 1\n",
      "2020-09-07 22:02:02,224: INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-07 22:02:02,224: INFO : EPOCH - 2 : training on 17005207 raw words (12819126 effective words) took 21.2s, 605184 effective words/s\n",
      "2020-09-07 22:02:03,229: INFO : EPOCH 3 - PROGRESS: at 4.94% examples, 631834 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:04,241: INFO : EPOCH 3 - PROGRESS: at 9.58% examples, 605465 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:05,262: INFO : EPOCH 3 - PROGRESS: at 13.70% examples, 575560 words/s, in_qsize 4, out_qsize 1\n",
      "2020-09-07 22:02:06,278: INFO : EPOCH 3 - PROGRESS: at 17.81% examples, 561026 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:07,289: INFO : EPOCH 3 - PROGRESS: at 22.40% examples, 564877 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:08,304: INFO : EPOCH 3 - PROGRESS: at 27.22% examples, 573189 words/s, in_qsize 6, out_qsize 1\n",
      "2020-09-07 22:02:09,303: INFO : EPOCH 3 - PROGRESS: at 31.75% examples, 575332 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:10,320: INFO : EPOCH 3 - PROGRESS: at 36.39% examples, 577453 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:11,327: INFO : EPOCH 3 - PROGRESS: at 41.15% examples, 580472 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:12,337: INFO : EPOCH 3 - PROGRESS: at 46.21% examples, 587033 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:13,340: INFO : EPOCH 3 - PROGRESS: at 51.32% examples, 593411 words/s, in_qsize 5, out_qsize 1\n",
      "2020-09-07 22:02:14,350: INFO : EPOCH 3 - PROGRESS: at 56.38% examples, 597947 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:15,353: INFO : EPOCH 3 - PROGRESS: at 61.32% examples, 600622 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:16,368: INFO : EPOCH 3 - PROGRESS: at 66.55% examples, 604875 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:17,373: INFO : EPOCH 3 - PROGRESS: at 71.19% examples, 604164 words/s, in_qsize 6, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-07 22:02:18,380: INFO : EPOCH 3 - PROGRESS: at 76.48% examples, 607840 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:19,402: INFO : EPOCH 3 - PROGRESS: at 81.60% examples, 609502 words/s, in_qsize 6, out_qsize 1\n",
      "2020-09-07 22:02:20,410: INFO : EPOCH 3 - PROGRESS: at 86.83% examples, 612508 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:21,413: INFO : EPOCH 3 - PROGRESS: at 91.95% examples, 614731 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:22,422: INFO : EPOCH 3 - PROGRESS: at 97.06% examples, 616313 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:22,969: INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-07 22:02:22,971: INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-07 22:02:22,978: INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-07 22:02:22,978: INFO : EPOCH - 3 : training on 17005207 raw words (12820503 effective words) took 20.8s, 617818 effective words/s\n",
      "2020-09-07 22:02:24,006: INFO : EPOCH 4 - PROGRESS: at 4.94% examples, 617607 words/s, in_qsize 4, out_qsize 2\n",
      "2020-09-07 22:02:25,010: INFO : EPOCH 4 - PROGRESS: at 9.82% examples, 615354 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:26,018: INFO : EPOCH 4 - PROGRESS: at 14.93% examples, 627389 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:27,017: INFO : EPOCH 4 - PROGRESS: at 20.05% examples, 633259 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:28,040: INFO : EPOCH 4 - PROGRESS: at 25.16% examples, 635702 words/s, in_qsize 6, out_qsize 1\n",
      "2020-09-07 22:02:29,041: INFO : EPOCH 4 - PROGRESS: at 30.34% examples, 641530 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:30,050: INFO : EPOCH 4 - PROGRESS: at 35.27% examples, 640438 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:31,060: INFO : EPOCH 4 - PROGRESS: at 40.39% examples, 641786 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:32,066: INFO : EPOCH 4 - PROGRESS: at 45.27% examples, 639844 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:33,070: INFO : EPOCH 4 - PROGRESS: at 50.21% examples, 639322 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:34,078: INFO : EPOCH 4 - PROGRESS: at 54.91% examples, 636084 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:35,083: INFO : EPOCH 4 - PROGRESS: at 59.91% examples, 636345 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:36,090: INFO : EPOCH 4 - PROGRESS: at 65.02% examples, 637322 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:37,095: INFO : EPOCH 4 - PROGRESS: at 70.02% examples, 637432 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:38,094: INFO : EPOCH 4 - PROGRESS: at 74.78% examples, 635777 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:39,107: INFO : EPOCH 4 - PROGRESS: at 79.84% examples, 635061 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:40,115: INFO : EPOCH 4 - PROGRESS: at 84.77% examples, 634562 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:41,120: INFO : EPOCH 4 - PROGRESS: at 89.89% examples, 635720 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:42,125: INFO : EPOCH 4 - PROGRESS: at 94.77% examples, 634701 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:43,134: INFO : EPOCH 4 - PROGRESS: at 99.76% examples, 634640 words/s, in_qsize 4, out_qsize 0\n",
      "2020-09-07 22:02:43,142: INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-07 22:02:43,157: INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-07 22:02:43,169: INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-07 22:02:43,171: INFO : EPOCH - 4 : training on 17005207 raw words (12818503 effective words) took 20.2s, 634894 effective words/s\n",
      "2020-09-07 22:02:44,181: INFO : EPOCH 5 - PROGRESS: at 4.88% examples, 619956 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:45,190: INFO : EPOCH 5 - PROGRESS: at 9.94% examples, 627267 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:46,196: INFO : EPOCH 5 - PROGRESS: at 15.11% examples, 637930 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:47,202: INFO : EPOCH 5 - PROGRESS: at 20.34% examples, 644516 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:48,210: INFO : EPOCH 5 - PROGRESS: at 25.51% examples, 647793 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:49,215: INFO : EPOCH 5 - PROGRESS: at 30.57% examples, 648655 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:50,215: INFO : EPOCH 5 - PROGRESS: at 35.51% examples, 647281 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:51,214: INFO : EPOCH 5 - PROGRESS: at 40.51% examples, 646444 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:52,222: INFO : EPOCH 5 - PROGRESS: at 45.44% examples, 644730 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:53,231: INFO : EPOCH 5 - PROGRESS: at 50.32% examples, 642714 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:54,238: INFO : EPOCH 5 - PROGRESS: at 55.32% examples, 642618 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:55,251: INFO : EPOCH 5 - PROGRESS: at 60.44% examples, 643339 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:02:56,259: INFO : EPOCH 5 - PROGRESS: at 65.49% examples, 643083 words/s, in_qsize 6, out_qsize 1\n",
      "2020-09-07 22:02:57,269: INFO : EPOCH 5 - PROGRESS: at 70.55% examples, 643147 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:58,271: INFO : EPOCH 5 - PROGRESS: at 75.01% examples, 638327 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:02:59,273: INFO : EPOCH 5 - PROGRESS: at 79.60% examples, 634171 words/s, in_qsize 4, out_qsize 1\n",
      "2020-09-07 22:03:00,281: INFO : EPOCH 5 - PROGRESS: at 84.48% examples, 633371 words/s, in_qsize 6, out_qsize 0\n",
      "2020-09-07 22:03:01,299: INFO : EPOCH 5 - PROGRESS: at 89.54% examples, 633634 words/s, in_qsize 5, out_qsize 1\n",
      "2020-09-07 22:03:02,302: INFO : EPOCH 5 - PROGRESS: at 94.65% examples, 634402 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:03:03,312: INFO : EPOCH 5 - PROGRESS: at 99.71% examples, 634812 words/s, in_qsize 5, out_qsize 0\n",
      "2020-09-07 22:03:03,345: INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-07 22:03:03,351: INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-07 22:03:03,355: INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-07 22:03:03,356: INFO : EPOCH - 5 : training on 17005207 raw words (12817181 effective words) took 20.2s, 635108 effective words/s\n",
      "2020-09-07 22:03:03,357: INFO : training on a 85026035 raw words (64093038 effective words) took 103.4s, 619935 effective words/s\n"
     ]
    }
   ],
   "source": [
    "#實體gensim模組\n",
    "model = gensim.models.Word2Vec(sentence, min_count=1, size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 已經用我們自己的語料庫建立一個word2vec模型，可以使用裡面所包含的字詞向量。每一個字詞都用20維的向量來表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.6589146 , -2.059375  , -0.8230269 ,  2.2753518 , -4.2195506 ,\n",
       "        2.453612  ,  0.90548056,  6.1119876 ,  2.3973694 ,  0.6910609 ,\n",
       "        1.8435425 ,  3.5594847 , -6.884309  ,  2.8693833 ,  0.28955057,\n",
       "        5.24688   ,  0.10235706, -0.23963721, -2.4963558 ,  2.7566025 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#獲得\"king\"字詞的向量\n",
    "model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-07 22:03:03,398: INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('emperor', 0.9057022333145142),\n",
       " ('son', 0.8896150588989258),\n",
       " ('charlemagne', 0.8806945085525513),\n",
       " ('tsar', 0.8794891834259033),\n",
       " ('empress', 0.8761159181594849),\n",
       " ('pope', 0.8669358491897583),\n",
       " ('consul', 0.8635085821151733),\n",
       " ('prince', 0.8602508902549744),\n",
       " ('elector', 0.850213885307312),\n",
       " ('ruler', 0.8485316634178162)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#進行向量計算觀察是否與我們想的一樣\n",
    "#女 + 國王 - 男 = 女王\n",
    "model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'Paris' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8b2ee352442a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#倫敦之餘英國相當於巴黎之於?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Paris'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'England'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'London'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'Paris' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "#倫敦之餘英國相當於巴黎之於?\n",
    "model.wv.most_similar(positive=['Paris', 'England'], negative=['London'], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 由國王女王可以看出，語料庫並沒有完全學習到我們想要的語意。而倫敦巴黎則是語料庫內並沒有巴黎這個字詞。這就顯示了__「字嵌入」會受限於所選擇的語料庫及計算字嵌入的機器__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-07 22:04:21,924: INFO : loading projection weights from ./data/GoogleNews-vectors-negative300.bin\n",
      "2020-09-07 22:05:01,986: INFO : loaded (3000000, 300) matrix from ./data/GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "#使用gensim事先訓練好的模型，由300萬個字詞訓練，每個字詞為300維度的向量表示方法\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./data/GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-3ebd0162574c>:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  len(model.wv.vocab)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#總共有300萬個單字\n",
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-bedfed373225>:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
      "2020-09-07 22:05:02,013: INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#女 + 國王 - 男 = 女王\n",
    "model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-8b2ee352442a>:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  model.wv.most_similar(positive=['Paris', 'England'], negative=['London'], topn=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('France', 0.667637825012207)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#倫敦之餘英國相當於巴黎之於?\n",
    "model.wv.most_similar(positive=['Paris', 'England'], negative=['London'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-47dca9e146d2>:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  model.wv.doesnt_match(\"duck bear cat tree\".split())\n",
      "c:\\python38\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tree'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#選出不屬於同一類別的字詞\n",
    "model.wv.doesnt_match(\"duck bear cat tree\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-15c196e667c4>:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  model.wv.similarity('woman', 'man')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76640123"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#女人和男人的相似度\n",
    "model.wv.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-729b02210595>:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  model.wv.similarity('tree', 'man')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22937459"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#樹和男人的相似度\n",
    "model.wv.similarity('tree', 'man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字嵌入應用:資訊檢索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先定義一個取得字嵌入的function\n",
    "def get_embedding(string):\n",
    "    try:\n",
    "        return model.wv[string]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立文章標題(我們要找尋的目標)\n",
    "sentence = [\n",
    "    \"this is about a dog\",\n",
    "    \"this is about a cat\",\n",
    "    \"this is about a nothing\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g']\n",
      "(<function <lambda> at 0x000001C07501F3A0>, [array([-0.38867188, -0.01287842,  0.15234375,  0.16015625, -0.11132812,\n",
      "       -0.00668335, -0.08300781, -0.15429688, -0.17382812, -0.03149414,\n",
      "       -0.08886719, -0.07519531, -0.32617188,  0.13085938, -0.14160156,\n",
      "        0.12695312, -0.23828125,  0.28320312, -0.22363281, -0.1171875 ,\n",
      "       -0.32617188,  0.00531006, -0.1640625 , -0.02990723,  0.01501465,\n",
      "        0.05249023, -0.35742188,  0.15039062, -0.0456543 , -0.05395508,\n",
      "        0.18945312, -0.08154297,  0.28515625, -0.09423828, -0.23828125,\n",
      "        0.16113281, -0.26953125,  0.2265625 , -0.12060547,  0.16601562,\n",
      "       -0.06396484,  0.04858398,  0.1953125 ,  0.26757812,  0.00086594,\n",
      "        0.01397705, -0.02416992, -0.05029297,  0.20019531,  0.02819824,\n",
      "       -0.08447266,  0.22753906, -0.17871094,  0.3984375 ,  0.18359375,\n",
      "       -0.03393555, -0.36328125, -0.33789062, -0.03393555, -0.21972656,\n",
      "       -0.10498047, -0.05493164, -0.24902344,  0.07373047,  0.16894531,\n",
      "       -0.42382812, -0.1171875 ,  0.03564453, -0.10595703, -0.00891113,\n",
      "       -0.0291748 , -0.13964844, -0.09863281, -0.09082031,  0.0703125 ,\n",
      "       -0.3828125 ,  0.07714844,  0.0456543 , -0.12304688, -0.25976562,\n",
      "       -0.234375  ,  0.07910156,  0.02038574, -0.0378418 ,  0.13476562,\n",
      "       -0.11816406, -0.04223633,  0.48828125,  0.08154297,  0.17871094,\n",
      "        0.00531006,  0.07128906,  0.04492188, -0.11572266,  0.41015625,\n",
      "        0.1796875 , -0.1640625 , -0.03979492,  0.2734375 ,  0.01989746,\n",
      "       -0.15332031, -0.171875  ,  0.06445312, -0.03808594, -0.13867188,\n",
      "        0.08251953, -0.02563477,  0.22558594, -0.05712891,  0.02148438,\n",
      "        0.0043335 , -0.0071106 ,  0.04321289,  0.00263977, -0.09765625,\n",
      "        0.2578125 ,  0.17480469, -0.02624512,  0.02099609, -0.03662109,\n",
      "        0.18359375,  0.02893066, -0.07373047,  0.04150391,  0.5       ,\n",
      "       -0.07373047,  0.27539062, -0.01385498,  0.22851562, -0.01342773,\n",
      "       -0.08984375,  0.14648438, -0.08300781,  0.13085938, -0.125     ,\n",
      "        0.12695312,  0.15722656, -0.09570312,  0.453125  ,  0.14160156,\n",
      "        0.13964844, -0.08056641, -0.19335938, -0.22070312,  0.02087402,\n",
      "       -0.10205078, -0.01385498,  0.31835938, -0.11035156,  0.01312256,\n",
      "        0.22460938, -0.41210938, -0.1796875 ,  0.11279297, -0.15917969,\n",
      "       -0.0456543 ,  0.03662109,  0.09033203,  0.06176758,  0.06689453,\n",
      "       -0.05810547,  0.21679688,  0.32226562,  0.03686523,  0.01226807,\n",
      "       -0.10400391, -0.02233887,  0.07177734, -0.02770996, -0.11572266,\n",
      "       -0.26171875, -0.16796875,  0.00613403,  0.15136719, -0.06445312,\n",
      "        0.02783203,  0.04418945, -0.36328125, -0.0123291 , -0.16699219,\n",
      "        0.24414062,  0.1484375 ,  0.1796875 ,  0.16308594,  0.01245117,\n",
      "        0.06201172, -0.11767578,  0.04882812, -0.18554688, -0.00723267,\n",
      "        0.21875   , -0.01574707, -0.24902344,  0.05883789,  0.03833008,\n",
      "        0.20410156, -0.05932617, -0.02526855,  0.13574219, -0.18457031,\n",
      "       -0.05322266,  0.19921875, -0.1328125 ,  0.03833008,  0.04101562,\n",
      "       -0.11328125, -0.24121094,  0.14746094, -0.03515625,  0.4375    ,\n",
      "        0.17773438, -0.16894531, -0.00260925,  0.04663086, -0.29101562,\n",
      "        0.05517578,  0.00964355, -0.10888672, -0.18554688,  0.0255127 ,\n",
      "       -0.13867188,  0.44140625,  0.05444336,  0.11376953,  0.09716797,\n",
      "       -0.01092529, -0.0090332 ,  0.08935547,  0.21484375, -0.18847656,\n",
      "        0.21484375,  0.01342773, -0.07861328, -0.01708984, -0.05004883,\n",
      "        0.1484375 ,  0.05444336,  0.07226562,  0.03222656,  0.22167969,\n",
      "       -0.04614258,  0.15234375,  0.38867188, -0.07763672,  0.01660156,\n",
      "        0.05786133, -0.30273438,  0.36328125,  0.03515625, -0.03344727,\n",
      "        0.15234375, -0.14160156,  0.09912109,  0.06542969, -0.01263428,\n",
      "       -0.27539062,  0.01379395, -0.1640625 ,  0.24804688,  0.06542969,\n",
      "        0.12158203,  0.06835938, -0.07177734, -0.03344727, -0.08544922,\n",
      "       -0.07421875,  0.07226562, -0.1328125 , -0.19628906, -0.18359375,\n",
      "       -0.14746094, -0.12988281, -0.10546875,  0.10107422,  0.04223633,\n",
      "       -0.26757812, -0.24121094, -0.27734375,  0.00360107,  0.09765625,\n",
      "       -0.03540039,  0.25585938,  0.0480957 , -0.0703125 , -0.38671875,\n",
      "       -0.02087402, -0.06787109, -0.13085938,  0.02783203, -0.21191406,\n",
      "        0.04931641, -0.08642578,  0.17480469,  0.14160156, -0.08251953,\n",
      "       -0.03076172, -0.20898438, -0.06933594, -0.1484375 ,  0.25390625],\n",
      "      dtype=float32)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-ccb9db7012b3>:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  return model.wv[string]\n"
     ]
    }
   ],
   "source": [
    "#將每一句話轉換成向量的形式，方法是透過將每一個字的字嵌入做加總平均\n",
    "#先建立一個3 X 300的零矩陣\n",
    "vectorized_sentence = np.zeros((len(sentence), 300))\n",
    "for i, sentence in enumerate(sentence):\n",
    "    #將單字切割\n",
    "    words = sentence.split(' ')\n",
    "    print(words)\n",
    "    \n",
    "    #進行字嵌入\n",
    "    embedded_words = [get_embedding(w) for w in words]\n",
    "    embedded_words = lambda x:x is not None, embedded_words\n",
    "    print(embedded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
